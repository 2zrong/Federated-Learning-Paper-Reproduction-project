{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "15mKd8YoC-3_",
        "outputId": "84177dd3-1108-4f10-faa0-f84ff3798f62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e273790e-5f08-418d-a55d-d78f94b37d9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e273790e-5f08-418d-a55d-d78f94b37d9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kvasir-seg.zip to kvasir-seg (1).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"kvasir-seg (1).zip\" -d /content/kvasir-seg"
      ],
      "metadata": {
        "id": "Pja16IprE2d4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"flwr<1.11.0\" numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqppJRRBujVP",
        "outputId": "5b284cf2-24be-4aaa-e90c-61ad26e82d0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr<1.11.0 in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: cryptography<43.0.0,>=42.0.4 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (42.0.8)\n",
            "Requirement already satisfied: grpcio!=1.64.2,!=1.65.1,<2.0.0,>=1.60.0 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (1.76.0)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (0.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.25.2 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (3.23.0)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (2.3.0)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from flwr<1.11.0) (1.2.0)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (0.9.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<43.0.0,>=42.0.4->flwr<1.11.0) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio!=1.64.2,!=1.65.1,<2.0.0,>=1.60.0->flwr<1.11.0) (4.15.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.12/dist-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (8.3.1)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (13.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr<1.11.0) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr<1.11.0) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from typing import Dict, Any, List, Tuple\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "tHrbFXuFumiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c778efb7-4a8f-475d-adef-7fbf3de298bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLIENT_ID = 2\n",
        "\n",
        "SERVER_ADDRESS = \"0.tcp.jp.ngrok.io:12014\""
      ],
      "metadata": {
        "id": "PvpBdLFzuozo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DATA_DIR = \"/content/kvasir-seg/Kvasir-SEG\""
      ],
      "metadata": {
        "id": "P3e_hRk1-gcP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KvasirSegDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - images/ 안의 파일과 masks/ 안의 파일을\n",
        "      '같은 이름 + (확장자만 다를 수 있음)' 기준으로 매칭\n",
        "    \"\"\"\n",
        "    def __init__(self, images_dir: str, masks_dir: str):\n",
        "        super().__init__()\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "\n",
        "        # 이미지 파일 후보들 (jpg/jpeg/png)\n",
        "        img_paths = sorted(\n",
        "            glob.glob(os.path.join(images_dir, \"*.jpg\"))\n",
        "            + glob.glob(os.path.join(images_dir, \"*.jpeg\"))\n",
        "            + glob.glob(os.path.join(images_dir, \"*.png\"))\n",
        "        )\n",
        "\n",
        "        if len(img_paths) == 0:\n",
        "            raise RuntimeError(f\"이미지 파일 없음: {images_dir}\")\n",
        "\n",
        "        self.pairs = []  # (img_path, mask_path) 리스트\n",
        "\n",
        "        for img_path in img_paths:\n",
        "            base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "            # 마스크는 png/jpg/jpeg 중 실제로 존재하는 걸 사용\n",
        "            cand_masks = [\n",
        "                os.path.join(masks_dir, base + ext)\n",
        "                for ext in [\".png\", \".jpg\", \".jpeg\"]\n",
        "            ]\n",
        "\n",
        "            mask_path = None\n",
        "            for cm in cand_masks:\n",
        "                if os.path.exists(cm):\n",
        "                    mask_path = cm\n",
        "                    break\n",
        "\n",
        "            if mask_path is None:\n",
        "                # 해당 이미지에 대응되는 마스크가 없으면 그냥 스킵\n",
        "                print(f\"[WARN] 마스크 없음, 스킵: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            self.pairs.append((img_path, mask_path))\n",
        "\n",
        "        if len(self.pairs) == 0:\n",
        "            raise RuntimeError(f\"매칭되는 이미지-마스크 쌍이 없습니다. masks 폴더 구조를 확인하세요.\")\n",
        "\n",
        "        print(f\"[INFO] 유효한 이미지-마스크 쌍 개수: {len(self.pairs)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def _load_and_preprocess(self, img_path, is_mask=False):\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if is_mask:\n",
        "            img = img.convert(\"L\")\n",
        "            img = img.resize((256, 256), resample=Image.NEAREST)\n",
        "        else:\n",
        "            img = img.convert(\"RGB\")\n",
        "            img = img.resize((256, 256), resample=Image.BILINEAR)\n",
        "            img = img.convert(\"L\")\n",
        "\n",
        "        arr = np.array(img, dtype=np.float32)\n",
        "\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, :, :]\n",
        "        else:\n",
        "            arr = arr.transpose(2, 0, 1)\n",
        "\n",
        "        arr = arr / 255.0\n",
        "        return torch.tensor(arr, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path = self.pairs[idx]\n",
        "\n",
        "        image = self._load_and_preprocess(img_path, is_mask=False)\n",
        "        mask = self._load_and_preprocess(mask_path, is_mask=True)\n",
        "        mask = (mask > 0.5).float()\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "def dirichlet_split_dataset(full_dataset, num_clients=3, alpha=0.5, client_id=0):\n",
        "    \"\"\"\n",
        "    Dirichlet(α) 기반으로 전체 데이터셋을 num_clients 개로 나눈 뒤,\n",
        "    해당 client_id 에 할당된 인덱스만 반환.\n",
        "\n",
        "    - alpha: Dirichlet α (논문에서는 1.0 / 0.5 / 0.1 사용)\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    dataset_size = len(full_dataset)\n",
        "    all_indices = np.arange(dataset_size)\n",
        "\n",
        "    # 각 클라이언트 비율을 Dirichlet 분포에서 샘플링\n",
        "    proportions = np.random.dirichlet([alpha] * num_clients)\n",
        "\n",
        "    # 비율 * 전체 개수 → 각 클라이언트가 가질 샘플 수\n",
        "    client_sizes = (proportions * dataset_size).astype(int)\n",
        "\n",
        "    # 반올림/내림 과정에서 빠진 샘플을 마지막 클라이언트에 몰아주기\n",
        "    client_sizes[-1] += dataset_size - client_sizes.sum()\n",
        "\n",
        "    np.random.shuffle(all_indices)\n",
        "\n",
        "    idx_map = {}\n",
        "    start = 0\n",
        "    for i in range(num_clients):\n",
        "        end = start + client_sizes[i]\n",
        "        idx_map[i] = all_indices[start:end]\n",
        "        start = end\n",
        "\n",
        "    client_indices = idx_map[client_id]\n",
        "    print(f\"[DIRICHLET] alpha={alpha}, client_id={client_id}, num_samples={len(client_indices)}\")\n",
        "\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def make_dataloaders(alpha=0.5, num_clients=3) -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    이 클라이언트가 사용할 trainloader, valloader 생성\n",
        "    - 논문과 동일하게 Dirichlet(α) 분포 기반 Non-IID 분할 적용\n",
        "    - 그다음, 이 클라이언트의 데이터만 8:2로 train/val로 나눔\n",
        "    \"\"\"\n",
        "\n",
        "    images_dir = os.path.join(BASE_DATA_DIR, \"images\")\n",
        "    masks_dir = os.path.join(BASE_DATA_DIR, \"masks\")\n",
        "\n",
        "    full_dataset = KvasirSegDataset(images_dir, masks_dir)\n",
        "\n",
        "    client_indices = dirichlet_split_dataset(\n",
        "        full_dataset=full_dataset,\n",
        "        num_clients=num_clients,\n",
        "        alpha=alpha,\n",
        "        client_id=CLIENT_ID,\n",
        "    )\n",
        "\n",
        "    # 이 클라이언트 전용 Subset\n",
        "    client_dataset = torch.utils.data.Subset(full_dataset, client_indices)\n",
        "\n",
        "    # 클라이언트 내부에서 8:2 비율로 train/val 분할\n",
        "    n_total = len(client_dataset)\n",
        "    n_train = int(n_total * 0.8)\n",
        "    n_val = n_total - n_train\n",
        "\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        client_dataset,\n",
        "        [n_train, n_val],\n",
        "        generator=torch.Generator().manual_seed(42),  # 재현성\n",
        "    )\n",
        "\n",
        "    trainloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    valloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "    return trainloader, valloader"
      ],
      "metadata": {
        "id": "7xvNkHvTuyqg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, out_channels: int = 1, features: int = 32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc1 = self._block(in_channels, features)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = self._block(features, features * 2)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = self._block(features * 2, features * 4)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n",
        "        self.dec2 = self._block(features * 4, features * 2)\n",
        "        self.up1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n",
        "        self.dec1 = self._block(features * 2, features)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(features, out_channels, kernel_size=1)\n",
        "\n",
        "    def _block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(self.pool1(x1))\n",
        "        x3 = self.bottleneck(self.pool2(x2))\n",
        "\n",
        "        x = self.up2(x3)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.dec2(x)\n",
        "\n",
        "        x = self.up1(x)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.dec1(x)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "\n",
        "def model_fn() -> nn.Module:\n",
        "    \"\"\"\n",
        "    Flower 클라이언트에서 사용할 모델 생성 함수\n",
        "    - 나중에 SimpleUNet 대신 논문 구조의 U-Net으로 교체하면 됨\n",
        "    \"\"\"\n",
        "    return SimpleUNet(in_channels=1, out_channels=1, features=32)"
      ],
      "metadata": {
        "id": "f5byxkrmu37P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(pred: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    세그멘테이션용 Dice Loss\n",
        "    pred: (B,1,H,W), sigmoid 이후 값\n",
        "    target: (B,1,H,W), 0/1 마스크\n",
        "    \"\"\"\n",
        "    pred_flat = pred.view(pred.size(0), -1)\n",
        "    target_flat = target.view(target.size(0), -1)\n",
        "\n",
        "    inter = (pred_flat * target_flat).sum(dim=1)\n",
        "    union = pred_flat.sum(dim=1) + target_flat.sum(dim=1)\n",
        "\n",
        "    dice = (2 * inter + eps) / (union + eps)\n",
        "    return 1 - dice.mean()"
      ],
      "metadata": {
        "id": "RsTldMz-u_J0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClient(fl.client.NumPyClient):\n",
        "    def __init__(self):\n",
        "        # 이 클라이언트의 ID (서버 쪽에서 구분용)\n",
        "        self.cid = str(CLIENT_ID)\n",
        "\n",
        "        # 모델, 데이터로더, 디바이스 준비\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model_fn().to(self.device)\n",
        "        self.trainloader, self.valloader = make_dataloaders()\n",
        "\n",
        "    # ---------- Flower 필수 메서드 1: get_parameters ----------\n",
        "    def get_parameters(self, config: Dict[str, Any]) -> List[np.ndarray]:\n",
        "        \"\"\"\n",
        "        서버가 \"초기 파라미터 보내줘\" 할 때 호출됨.\n",
        "        모델의 state_dict를 numpy 배열 리스트로 변환해서 반환.\n",
        "        \"\"\"\n",
        "        state_dict = self.model.state_dict()\n",
        "        return [v.cpu().numpy() for _, v in state_dict.items()]\n",
        "\n",
        "    # ---------- Flower 필수 메서드 2: set_parameters ----------\n",
        "    def set_parameters(self, parameters: List[np.ndarray]) -> None:\n",
        "        \"\"\"\n",
        "        서버에서 내려준 글로벌 파라미터를 로컬 모델에 로드.\n",
        "        \"\"\"\n",
        "        state_dict = self.model.state_dict()\n",
        "        new_state = {}\n",
        "        for (k, _), p in zip(state_dict.items(), parameters):\n",
        "            new_state[k] = torch.tensor(p)\n",
        "        self.model.load_state_dict(new_state, strict=True)\n",
        "\n",
        "    # ---------- Flower 필수 메서드 3: fit (로컬 학습) ----------\n",
        "    def fit(\n",
        "        self,\n",
        "        parameters: List[np.ndarray],\n",
        "        config: Dict[str, Any],\n",
        "    ) -> Tuple[List[np.ndarray], int, Dict[str, Any]]:\n",
        "\n",
        "        # 1) 글로벌 파라미터 적용\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.to(self.device)\n",
        "        self.model.train()\n",
        "\n",
        "        # 2) 서버가 fit_config로 내려준 설정 사용\n",
        "        local_epochs = int(config.get(\"local_epochs\", 1))\n",
        "        lr = float(config.get(\"learning_rate\", 1e-3))\n",
        "        batch_size = int(config.get(\"batch_size\", 32))\n",
        "        rnd = int(config.get(\"round\", -1))\n",
        "\n",
        "        print(f\"[CLIENT {self.cid}] Round {rnd} | epochs={local_epochs}, lr={lr}, bs={batch_size}\")\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_dice = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        for epoch in range(local_epochs):\n",
        "            for images, masks in self.trainloader:\n",
        "                images = images.to(self.device)\n",
        "                masks = masks.to(self.device)\n",
        "\n",
        "                logits = self.model(images)\n",
        "                probs = torch.sigmoid(logits)\n",
        "\n",
        "                loss = dice_loss(probs, masks)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                running_dice += (1.0 - loss.item())\n",
        "                num_batches += 1\n",
        "\n",
        "        avg_loss = running_loss / max(1, num_batches)\n",
        "        avg_dice = running_dice / max(1, num_batches)\n",
        "\n",
        "        print(f\"[CLIENT {self.cid}] Round {rnd} | train_loss={avg_loss:.4f}, train_dice={avg_dice:.4f}\")\n",
        "\n",
        "        # 3) 업데이트된 파라미터 반환\n",
        "        state_dict = self.model.state_dict()\n",
        "        new_params = [v.detach().cpu().numpy() for _, v in state_dict.items()]\n",
        "        num_examples = len(self.trainloader.dataset)\n",
        "\n",
        "        metrics = {\n",
        "            \"train_loss\": float(avg_loss),\n",
        "            \"train_dice\": float(avg_dice),\n",
        "        }\n",
        "\n",
        "        return new_params, num_examples, metrics\n",
        "\n",
        "    # ---------- Flower 필수 메서드 4: evaluate (로컬 평가) ----------\n",
        "    def evaluate(\n",
        "        self,\n",
        "        parameters: List[np.ndarray],\n",
        "        config: Dict[str, Any],\n",
        "    ) -> Tuple[float, int, Dict[str, Any]]:\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_dice = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, masks in self.valloader:\n",
        "                images = images.to(self.device)\n",
        "                masks = masks.to(self.device)\n",
        "\n",
        "                logits = self.model(images)\n",
        "                probs = torch.sigmoid(logits)\n",
        "\n",
        "                l = dice_loss(probs, masks)\n",
        "                total_loss += l.item()\n",
        "                total_dice += (1.0 - l.item())\n",
        "                num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / max(1, num_batches)\n",
        "        avg_dice = total_dice / max(1, num_batches)\n",
        "        num_examples = len(self.valloader.dataset)\n",
        "\n",
        "        print(f\"[CLIENT {self.cid}] Eval | loss={avg_loss:.4f}, dice={avg_dice:.4f}\")\n",
        "\n",
        "        return float(avg_loss), num_examples, {\"val_dice\": float(avg_dice)}"
      ],
      "metadata": {
        "id": "QGXA8iUtvC_1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[CLIENT {CLIENT_ID}] Connecting...\") # 서버 연결 부분 수정X\n",
        "fl.client.start_client(\n",
        "    server_address=SERVER_ADDRESS,\n",
        "    client=SimpleClient().to_client(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNXsa546vQCX",
        "outputId": "4c75ac56-893e-41fa-ab3e-0669f7e39fb7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Opened insecure gRPC connection (no certificates were passed)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "DEBUG:flwr:ChannelConnectivity.IDLE\n",
            "DEBUG:flwr:ChannelConnectivity.CONNECTING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Connecting...\n",
            "[INFO] 유효한 이미지-마스크 쌍 개수: 1000\n",
            "[DIRICHLET] alpha=0.5, client_id=2, num_samples=30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:ChannelConnectivity.READY\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: train message 57bb6e79-b855-4750-87bd-eb310b09c302\n",
            "INFO:flwr:Received: train message 57bb6e79-b855-4750-87bd-eb310b09c302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 1 | epochs=1, lr=0.001, bs=32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 1 | train_loss=0.7719, train_dice=0.2281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: evaluate message 93785f07-a713-47e6-8ef0-60b6a03798a5\n",
            "INFO:flwr:Received: evaluate message 93785f07-a713-47e6-8ef0-60b6a03798a5\n",
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Eval | loss=0.6388, dice=0.3612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: train message 7efa41ac-5fb7-4e5c-bcd9-fe30ccc5ce90\n",
            "INFO:flwr:Received: train message 7efa41ac-5fb7-4e5c-bcd9-fe30ccc5ce90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 2 | epochs=1, lr=0.001, bs=32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 2 | train_loss=0.6823, train_dice=0.3177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: evaluate message b7eb2c16-d6f9-4d6f-a637-593ebe2fc1ea\n",
            "INFO:flwr:Received: evaluate message b7eb2c16-d6f9-4d6f-a637-593ebe2fc1ea\n",
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Eval | loss=0.4657, dice=0.5343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: train message 39c32ab6-193a-4fb2-95c4-8cddb97c5509\n",
            "INFO:flwr:Received: train message 39c32ab6-193a-4fb2-95c4-8cddb97c5509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 3 | epochs=1, lr=0.001, bs=32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 3 | train_loss=0.6501, train_dice=0.3499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: evaluate message aad0ecb0-9a16-412e-ad9e-0fbc2e0997f2\n",
            "INFO:flwr:Received: evaluate message aad0ecb0-9a16-412e-ad9e-0fbc2e0997f2\n",
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Eval | loss=0.4269, dice=0.5731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: train message be9d0d89-740d-4930-8325-f6bf11bd5dcf\n",
            "INFO:flwr:Received: train message be9d0d89-740d-4930-8325-f6bf11bd5dcf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 4 | epochs=1, lr=0.001, bs=32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 4 | train_loss=0.6368, train_dice=0.3632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: evaluate message c8d0a470-39f1-43a8-a556-9c63142bfa20\n",
            "INFO:flwr:Received: evaluate message c8d0a470-39f1-43a8-a556-9c63142bfa20\n",
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Eval | loss=0.4262, dice=0.5738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: train message c02f59d6-140b-4ac6-b11d-17ac568c95ba\n",
            "INFO:flwr:Received: train message c02f59d6-140b-4ac6-b11d-17ac568c95ba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 5 | epochs=1, lr=0.001, bs=32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Round 5 | train_loss=0.6395, train_dice=0.3605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: evaluate message 82f2fff3-dae4-4816-8aa9-869b21e5fe86\n",
            "INFO:flwr:Received: evaluate message 82f2fff3-dae4-4816-8aa9-869b21e5fe86\n",
            "\u001b[92mINFO \u001b[0m:      Sent reply\n",
            "INFO:flwr:Sent reply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIENT 2] Eval | loss=0.4840, dice=0.5160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      Received: reconnect message b2578d99-dd97-4a7f-b914-3930443c1cb2\n",
            "INFO:flwr:Received: reconnect message b2578d99-dd97-4a7f-b914-3930443c1cb2\n",
            "DEBUG:flwr:gRPC channel closed\n",
            "\u001b[92mINFO \u001b[0m:      Disconnect and shut down\n",
            "INFO:flwr:Disconnect and shut down\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    }
  ]
}